{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3Jp_VhCl4te",
    "tags": []
   },
   "source": [
    "# CSE 252A Computer Vision I Fall 2021 - Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gISBijp3l4ti",
    "tags": []
   },
   "source": [
    "## Instructor: Ben Ochoa\n",
    "\n",
    "- Assignment Published On: **Wed, November 17, 2021**.\n",
    "\n",
    "- Due On: **Wed, December 1, 2021 11:59 PM (Pacific Time)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOXXS2dOl4tj",
    "tags": []
   },
   "source": [
    "## Instructions\n",
    "* This assignment must be completed **individually**. For more details, please follow the Academic Integrity Policy and Collaboration Policy on [Canvas](https://canvas.ucsd.edu/courses/21788).\n",
    "* All solutions must be written in this notebook.\n",
    "  * **If** it includes the theoretical problems, you **must** write your answers in Markdown cells (using LaTeX when appropriate).\n",
    "  * Programming aspects of the assignment must be completed using Python in this notebook.\n",
    "* You may use Python packages (such as `NumPy` and `SciPy`) for basic linear algebra, but you may not use packages that directly solve the problem.\n",
    "  * If you are unsure about using a specific package or function, then ask the instructor and/or teaching assistants for clarification.\n",
    "* You must submit this notebook exported as a PDF that contains separate pages. You must also submit this notebook as `.ipynb` file.\n",
    "  * Submit both files (`.pdf` and `.ipynb`) on Gradescope.\n",
    "  * **You must mark the PDF pages associated with each question in Gradescope. If you fail to do so, we may dock points.**\n",
    "* It is highly recommended that you begin working on this assignment early.\n",
    "* **Late Policy:** Assignments submitted late will receive a 15% grade reduction for each 12 hours late (i.e., 30% per day). Assignments will not be accepted 72 hours after the due date. If you require an extension (for personal reasons only) to a due date, you must request one as far in advance as possible. Extensions requested close to or after the due date will only be granted for clear emergencies or clearly unforeseeable circumstances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5pbyh5yl4tk",
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Problem 1: Machine Learning [28 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m16Ecnjdl4tk"
   },
   "source": [
    "In this problem, you will implement several machine learning solutions for computer vision problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fRmEALQpmG5_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Users/kaitheuser/opt/anaconda3/lib/python3.7/site-packages (0.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/kaitheuser/opt/anaconda3/lib/python3.7/site-packages (from sklearn) (0.22.1)\r\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Users/kaitheuser/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/kaitheuser/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.14.1)\r\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/kaitheuser/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQpyhnvIl4tk"
   },
   "source": [
    "### Problem 1.1: Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCC0JD1Il4tl"
   },
   "source": [
    "We will use [Scikit-learn (Sklearn)](https://scikit-learn.org/stable/) module in for this problem. It is the most useful and robust library for machine learning in Python. It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python. This library, which is largely written in Python, is built upon NumPy, SciPy and Matplotlib. \n",
    "\n",
    "Get started by installing the Sklearn module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8ZiYlaSol4tm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SQL5iPKl4to"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>\n",
    "\n",
    "### Problem 1.2: Download MNIST data [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_f1_Tz7l4tq"
   },
   "source": [
    "The [MNIST database](http://yann.lecun.com/exdb/mnist/) (Modified National Institute of Standards and Technology database) is a well-known dataset consisting of 28x28 grayscale images of handwritten digits. For this problem, we will use Sklearn to do machine learning classification on the MNIST database.\n",
    "\n",
    "Sklearn provides a subset of MNIST database with 8x8 pixel images of digits. The `images` attribute of the dataset stores 8x8 arrays of grayscale values for each image. The `target` attribute of the dataset stores the digit each image represents. Complete `plot_mnist_sample()` to plot a 2x5 figure, each grid lies a sample image from a category. The following image gives an example:\n",
    "<img src=\"fig/eg_mnist.PNG\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "<!-- ![MNIST EXAMPLE](./fig/eg_mnist.PNG =250x) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vbXpRqO1l4tq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3PTXSZhWl4tr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (1797, 64)\n",
      "Label Data Shape (1797,)\n"
     ]
    }
   ],
   "source": [
    "# Download MNIST Dataset from Sklearn\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Print to show there are 1797 images (8 by 8 images for a dimensionality of 64)\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "\n",
    "# Print to show there are 1797 labels (integers from 0-9)\n",
    "print(\"Label Data Shape\", digits.target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p43geFB4l4tr"
   },
   "outputs": [],
   "source": [
    "def plot_mnist_sample():\n",
    "    \"\"\"\n",
    "    This function plots a sample image for each category,\n",
    "    The result is a figure with 2x5 grid of images.\n",
    "    \n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    \n",
    "    \"\"\" ==========\n",
    "    YOUR CODE HERE\n",
    "    ========== \"\"\"\n",
    "    \n",
    "    # Store all the diffferent labels\n",
    "    labels = np.unique(digits.target)\n",
    "    \n",
    "    # Determine the total number of labels\n",
    "    num_Labels = len(labels)\n",
    "    \n",
    "    # Plot each category sample image\n",
    "    for label in range(0, num_Labels):\n",
    "        \n",
    "        # Run through the label array\n",
    "        for idx in range(0, digits.target.shape[0]):\n",
    "            \n",
    "            # If the element of the label array is the expected label\n",
    "            if digits.target[idx] == label:\n",
    "                \n",
    "                # Plot it.\n",
    "                img = digits.data[idx] # Get Image\n",
    "                plt.subplot(2, 5, label+1) # Create subplots\n",
    "                plot_Header = \"Train: \"+ str(label) # Plot title\n",
    "                plt.title(plot_Header) # Include headers\n",
    "                plt.xticks([]) # Remove x-axis ticks\n",
    "                plt.yticks([]) # Remove y-axis ticks\n",
    "                plt.imshow(img.reshape((8,8)), cmap ='gray') # Plot the sample image\n",
    "                \n",
    "                break\n",
    "                \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xEj8kOdul4tr"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT CODE: DO NOT CHANGE\n",
    "# This code is for you to plot the results.\n",
    "\n",
    "plot_mnist_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sD68VE3pl4ts"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>\n",
    "\n",
    "### Problem 1.3: Recognizing hand-written digits with Sklearn [5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ctL_Gwl4ts"
   },
   "source": [
    "One of the most amazing things about Sklearn library is that it provides an easy pattern for you to call different models. In this part, we will get some experience with several classifiers in Sklearn. You will complete `LogisticRegressionClassifier` and `kNNCalssifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bDZ8BK3Ol4ts"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "#### Some helper functions are given below####\n",
    "def DataBatch(data, label, batchsize, shuffle=True):\n",
    "    \"\"\"\n",
    "    This function provides a generator for batches of data that \n",
    "    yields data (batchsize, 3, 32, 32) and labels (batchsize)\n",
    "    if shuffle, it will load batches in a random order\n",
    "    \"\"\"\n",
    "    n = data.shape[0]\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(n)\n",
    "    else:\n",
    "        index = np.arange(n)\n",
    "    for i in range(int(np.ceil(n/batchsize))):\n",
    "        inds = index[i*batchsize : min(n,(i+1)*batchsize)]\n",
    "        yield data[inds], label[inds]\n",
    "\n",
    "def test(testData, testLabels, classifier):\n",
    "    \"\"\"\n",
    "    Call this function to test the accuracy of a classifier\n",
    "    \"\"\"\n",
    "    batchsize=50\n",
    "    correct=0.\n",
    "    for data,label in DataBatch(testData,testLabels,batchsize,shuffle=False):\n",
    "        prediction = classifier(data)\n",
    "        correct += np.sum(prediction==label)\n",
    "    return correct/testData.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QQ0N2RCZl4tt"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "# Split data into 50% train and 50% test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.images.reshape((len(digits.images), -1)), digits.target, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m6JnXh3jl4tt"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class RandomClassifier():\n",
    "    \"\"\"\n",
    "    This is a sample classifier. \n",
    "    given an input it outputs a random class\n",
    "    \"\"\"\n",
    "    def __init__(self, classes=10):\n",
    "        self.classes=classes\n",
    "    def __call__(self, x):\n",
    "        return np.random.randint(self.classes, size=x.shape[0])\n",
    "    \n",
    "class LogisticRegressionClassifier():\n",
    "    def __init__(self, sol='liblinear'):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        # Initialize and Create the Logistic Regression Classifier object.\n",
    "        self.lrClassifier = LogisticRegression(solver = sol)\n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        # Fit the train data with the train labels.\n",
    "        self.lrClassifier.fit(trainData, trainLabels)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        return self.lrClassifier.predict(x)\n",
    "    \n",
    "class kNNClassifier():\n",
    "    def __init__(self, k=3):\n",
    "        \"\"\"\n",
    "         k is the number of neighbors involved in voting\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        # Initialize and Create the KNN Classifier object.\n",
    "        self.knnClassifier = KNeighborsClassifier(n_neighbors = k)\n",
    "        \n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        # Fit the train data with the train labels.\n",
    "        self.knnClassifier.fit(trainData, trainLabels)\n",
    "       \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        this method should take a batch of images and return a batch of predictions\n",
    "        \"\"\"\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        return self.knnClassifier.predict(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZQ9k9kw-l4tt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random classifier accuracy: 9.899889\n"
     ]
    }
   ],
   "source": [
    "# TEST CODE: DO NOT CHANGE\n",
    "randomClassifierX = RandomClassifier()\n",
    "print ('Random classifier accuracy: %f'%test(X_test, y_test, randomClassifierX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tOGbN8GDl4tu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classifier classifier accuracy: 91.657397\n"
     ]
    }
   ],
   "source": [
    "# TEST CODE: DO NOT CHANGE\n",
    "# TEST LogisticRegressionClassifier\n",
    "\n",
    "lrClassifierX = LogisticRegressionClassifier()\n",
    "lrClassifierX.train(X_train, y_train)\n",
    "print ('Logistic Regression Classifier classifier accuracy: %f'%test(X_test, y_test, lrClassifierX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WN3IyTafl4tu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier classifier accuracy: 96.329255\n"
     ]
    }
   ],
   "source": [
    "# TEST CODE: DO NOT CHANGE\n",
    "# TEST kNNClassifier\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "knnClassifierX = kNNClassifier()\n",
    "knnClassifierX.train(X_train, y_train)\n",
    "print ('KNN Classifier classifier accuracy: %f'%test(X_test, y_test, knnClassifierX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt39SvrEl4tv"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>\n",
    "\n",
    "### Problem 1.4: Confusion Matrix [5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jm0Zmzcl4tv"
   },
   "source": [
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. Here you will implement a function that computes the confusion matrix for a classifier. The matrix (M) should be $n \\times n$ where $n$ is the number of classes. Entry `M[i,j]` should contain the fraction of images of class `i` that was classified as class `j`. The following example plots confusion matrix for the `RandomClassifier`, your task is to plot the results for `LogisticRegressionClassifier` and `kNNClassifier`.\n",
    "<img src=\"fig/eg_confusion.PNG\" alt=\"drawing\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HP43z3lOl4tv"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def Confusion(testData, testLabels, classifier):\n",
    "    batchsize=50\n",
    "    correct=0\n",
    "    M=np.zeros((10,10))\n",
    "    num=testData.shape[0]/batchsize\n",
    "    count=0\n",
    "    acc=0\n",
    "    \n",
    "    for data,label in tqdm(DataBatch(testData,testLabels,batchsize,shuffle=False),total=len(testData)//batchsize):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "        # Get the predicted labels from the classifier.\n",
    "        label_prediction = classifier(data)\n",
    "        \n",
    "        # Construct the Confusion Matrix\n",
    "        for idx in range(0, label_prediction.shape[0]):\n",
    "            \n",
    "            # Count the number of occurance at each coordinate\n",
    "            M[label[idx], label_prediction[idx]] = M[label[idx], label_prediction[idx]] + 1\n",
    "    \n",
    "    # Get the total number of correct classification.\n",
    "    acc = np.trace(M)\n",
    "        \n",
    "    # Calculate the correct classification fraction of each category\n",
    "    for idx in range(0, M.shape[0]):\n",
    "    \n",
    "        # Get the the sum of each label\n",
    "        sum_of_label = np.sum(M[idx,:])\n",
    "        \n",
    "        # Construct the final Confusion Matrix\n",
    "        M[idx, :] = M[idx, :] / sum_of_label\n",
    "    \n",
    "    return M,acc*100.0/len(testData)\n",
    "\n",
    "def VisualizeConfussion(M):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.imshow(M)\n",
    "    plt.show()\n",
    "    print(np.round(M,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "suvefA82l4tv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 3504.50it/s]                                                       \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97 0.   0.   0.   0.01 0.01 0.01 0.   0.   0.  ]\n",
      " [0.   0.89 0.   0.01 0.   0.   0.01 0.   0.02 0.07]\n",
      " [0.02 0.   0.98 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.01 0.   0.82 0.   0.07 0.   0.02 0.05 0.02]\n",
      " [0.01 0.02 0.   0.   0.93 0.   0.01 0.   0.   0.02]\n",
      " [0.   0.03 0.   0.   0.   0.9  0.02 0.   0.   0.04]\n",
      " [0.   0.   0.01 0.   0.   0.   0.99 0.   0.   0.  ]\n",
      " [0.   0.01 0.   0.   0.   0.06 0.   0.89 0.01 0.03]\n",
      " [0.   0.06 0.01 0.   0.   0.03 0.01 0.   0.88 0.01]\n",
      " [0.02 0.01 0.   0.   0.   0.02 0.   0.   0.02 0.92]]\n"
     ]
    }
   ],
   "source": [
    "# TEST/PLOT CODE: DO NOT CHANGE\n",
    "# TEST LogisticRegressionClassifier\n",
    "\n",
    "M,acc = Confusion(X_test, y_test, lrClassifierX)\n",
    "VisualizeConfussion(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YWZFcKjal4tw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 365.76it/s]                                                        \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99 0.   0.   0.   0.01 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.99 0.   0.   0.   0.   0.   0.   0.01 0.  ]\n",
      " [0.01 0.   0.94 0.05 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.92 0.   0.01 0.   0.02 0.03 0.01]\n",
      " [0.   0.   0.   0.   0.93 0.   0.   0.   0.   0.07]\n",
      " [0.   0.   0.   0.   0.   0.97 0.01 0.   0.   0.02]\n",
      " [0.   0.   0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   1.   0.   0.  ]\n",
      " [0.   0.02 0.01 0.01 0.   0.   0.   0.   0.95 0.  ]\n",
      " [0.   0.   0.   0.03 0.   0.02 0.   0.   0.01 0.93]]\n"
     ]
    }
   ],
   "source": [
    "# TEST/PLOT CODE: DO NOT CHANGE\n",
    "# TEST kNNClassifier\n",
    "\n",
    "M,acc = Confusion(X_test, y_test, knnClassifierX)\n",
    "VisualizeConfussion(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HnFGSRFl4tw"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>\n",
    "\n",
    "### Problem 1.5: K-Nearest Neighbors (KNN) [7 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l8Vxkoil4tw"
   },
   "source": [
    "For this problem, you will complete a simple kNN classifer without Sklearn. The distance metric is Euclidean distance (L2 norm) in pixel space. $k$ refers to the number of neighbors involved in voting on the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "C-D-znLZl4tx"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "class kNNClassifierManual():\n",
    "    def __init__(self, k=3):\n",
    "        self.k=k\n",
    "\n",
    "    def train(self, trainData, trainLabels):\n",
    "        #print(\"Called!\")\n",
    "        #print(trainData.shape, trainLabels.shape)\n",
    "        self.X_train = trainData\n",
    "        self.y_train = trainLabels\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        \n",
    "        # Initialize predicted labels\n",
    "        predicted_labels = []\n",
    "        \n",
    "        # Calculate the L2 distance between the test and train values.\n",
    "        for idx in range(0, X.shape[0]):\n",
    "            \n",
    "            # Initialize the L2 norm distance list\n",
    "            L2_dist = []\n",
    "            \n",
    "            # Initialize voting list\n",
    "            voting_list = []\n",
    "            \n",
    "            #print(self.X_train.shape, X.shape)\n",
    "            \n",
    "            # Loop through every samples\n",
    "            for i in range(0, self.X_train.shape[0]):\n",
    "                \n",
    "                #print(self.X_train[i].shape, X[idx].shape)\n",
    "                \n",
    "                # Calculate the difference between the test and train values\n",
    "                delta = self.X_train[i] - X[idx]\n",
    "                \n",
    "                # Square the delta\n",
    "                delta_sq = delta**2\n",
    "                \n",
    "                # Calculate the distance\n",
    "                distance = np.sqrt(np.sum(delta_sq))\n",
    "                \n",
    "                # Add to the L2 dist list together with the index.\n",
    "                L2_dist.append([distance, i])\n",
    "                \n",
    "            # Sort from lowest distance to highest distance\n",
    "            L2_dist.sort()\n",
    "            \n",
    "            # Select the nearest k from the L2_dist list\n",
    "            L2_dist_k = L2_dist[0: self.k]\n",
    "            \n",
    "            for j in range(0, self.k):\n",
    "                \n",
    "                # Get the labels that have the k nearest distance\n",
    "                voting_list.append(self.y_train[L2_dist_k[j][1]])\n",
    "            \n",
    "            # Get the most common/counter array of the lists\n",
    "            # Then get the first list, and then the first array of labels.\n",
    "            #print(voting_list)\n",
    "            #print(Counter(voting_list))\n",
    "            #print(Counter(voting_list).most_common(1))\n",
    "            voting_results = Counter(voting_list).most_common(1)[0][0]\n",
    "            \n",
    "            # Add to the predicted label list\n",
    "            predicted_labels.append(voting_results)\n",
    "            \n",
    "        # Convert to array\n",
    "        predicted_labels = np.array(predicted_labels)\n",
    "                \n",
    "        return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wPVvwhp0l4tx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier accuracy: 95.884316\n"
     ]
    }
   ],
   "source": [
    "# TEST/PLOT CODE: DO NOT CHANGE\n",
    "# TEST kNNClassifierManual\n",
    "\n",
    "knnClassifierManualX = kNNClassifierManual()\n",
    "knnClassifierManualX.train(X_train, y_train)\n",
    "print ('KNN classifier accuracy: %f'%test(X_test, y_test, knnClassifierManualX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZQQIiKPnRQF"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>\n",
    "\n",
    "### Problem 1.6: Principal Component Analysis (PCA) K-Nearest Neighbors (KNN) [8 pts]\n",
    "Here you will implement a simple KNN classifer in PCA space (for k=3 and 25 principal components).\n",
    "You should implement PCA yourself using svd (you may not use sklearn.decomposition.PCA\n",
    "or any other package that directly implements PCA transformations)\n",
    "\n",
    "Is the testing time for PCA KNN classifier more or less than that for KNN classifier? Comment on why it differs if it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "e06z90dxm7Af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA KNN classifier accuracy: 85.428254\n"
     ]
    }
   ],
   "source": [
    "class PCAKNNClassifer():\n",
    "    def __init__(self, components=25, k=3):\n",
    "        # components = number of principal components\n",
    "        # k is the number of neighbors involved in voting\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        # Initialize the object variables\n",
    "        self.components = components\n",
    "        self.k = k\n",
    "        self.classifier = kNNClassifierManual(k = self.k)\n",
    "        #self.classifier = KNeighborsClassifier(n_neighbors = self.k)\n",
    "        \n",
    "    def train(self, trainData, trainLabels):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        # Compute the mean image\n",
    "        mean_img = np.mean(trainData, axis=0)\n",
    "        \n",
    "        # Compute the covariance matrix\n",
    "        cov_Mat = np.dot((trainData - mean_img).T, (trainData - mean_img)) / (trainData.shape[0] - 1)\n",
    "        \n",
    "        # Check the covariance matrix with numpy\n",
    "        #cov_Mat = np.cov(trainData.T)\n",
    "        #print(cov_Mat)\n",
    "        \n",
    "        # Compute SVD on the covariance matrix\n",
    "        U, Sig, V_trans = np.linalg.svd(cov_Mat)\n",
    "        \n",
    "        # Get the first k rows of V_transpose which are the principal components and change to V\n",
    "        self.V_mat = V_trans[:self.components].T\n",
    "        \n",
    "        # Determine the projection of the trainData, A = XV.\n",
    "        #self.A_train_projected = np.dot(trainData, self.V_mat)\n",
    "        self.X_train = np.dot(trainData, self.V_mat)\n",
    "        self.y_train = trainLabels\n",
    "        \n",
    "        # Check the shape of the X_train and y_train\n",
    "        #print(self.X_train.shape, self.y_train.shape)\n",
    "        \n",
    "        # Pass the train images and train labels to the classifier.\n",
    "        self.classifier.train(self.X_train, self.y_train)\n",
    "        #self.classifier.fit(self.X_train, self.y_train)\n",
    "\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # this method should take a batch of images\n",
    "        # and return a batch of predictions\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        #print(x.shape)\n",
    "        # Determine the projection of the x test, A = XV.\n",
    "        self.A_test_projected = np.dot(x, self.V_mat)\n",
    "        \n",
    "        # Check the shape of the A_test_projected\n",
    "        #print(self.A_test_projected.shape)\n",
    "        \n",
    "        # Predict the labels with the knnClassifierManual\n",
    "        #return self.classifier.predict(self.A_test_projected)\n",
    "        return self.classifier(self.A_test_projected)\n",
    "\n",
    "# test your classifier with only the first 100 training examples (use this\n",
    "# while debugging)\n",
    "pcaknnClassiferX = PCAKNNClassifer()\n",
    "pcaknnClassiferX.train(X_train[:100], y_train[:100])\n",
    "print ('PCA KNN classifier accuracy: %f'%test(X_test, y_test, pcaknnClassiferX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eSbD_cdeoOY5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PCA KNN Classifier Computational Time:  6.435882091522217  s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:06,  2.76it/s]                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA KNN classifier accuracy: 95.661846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99 0.   0.   0.   0.01 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.96 0.02 0.   0.   0.   0.   0.   0.01 0.01]\n",
      " [0.01 0.   0.94 0.05 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.9  0.   0.02 0.   0.03 0.04 0.  ]\n",
      " [0.   0.   0.   0.   0.95 0.   0.   0.   0.   0.05]\n",
      " [0.   0.   0.   0.   0.   0.98 0.01 0.   0.   0.01]\n",
      " [0.   0.   0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.98 0.02 0.  ]\n",
      " [0.   0.02 0.   0.02 0.   0.   0.   0.01 0.94 0.  ]\n",
      " [0.   0.   0.   0.04 0.   0.02 0.   0.   0.   0.93]]\n"
     ]
    }
   ],
   "source": [
    "# Determine the compute time\n",
    "start_STOPWATCH = time.time()\n",
    "\n",
    "# Rerun pca knn again without confusion matrix\n",
    "pcaknnClassifer = PCAKNNClassifer()\n",
    "pcaknnClassifer.train(X_train, y_train)\n",
    "test(X_test, y_test, pcaknnClassifer)\n",
    "\n",
    "# Stop the stopwatch\n",
    "stop_STOPWATCH = time.time()\n",
    "# Record time\n",
    "print(\"\\n\\nPCA KNN Classifier Computational Time: \", time.time() - start_STOPWATCH, \" s\")\n",
    "\n",
    "# test your classifier with all the training examples\n",
    "pcaknnClassifer = PCAKNNClassifer()\n",
    "pcaknnClassifer.train(X_train, y_train)\n",
    "\n",
    "# display confusion matrix for your PCA KNN classifier with all the training examples\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "# Get the confusion matrix and the overall accuracy of the pcaknnClassiferX\n",
    "M_pca, acc_pca = Confusion(X_test, y_test, pcaknnClassifer)\n",
    "\n",
    "print ('PCA KNN classifier accuracy: %f'%acc_pca)\n",
    "VisualizeConfussion(M_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "KNN Classifier without PCA Computational Time:  6.230615854263306  s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:06,  2.93it/s]                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier without PCA accuracy: 95.884316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99 0.   0.   0.   0.01 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.97 0.01 0.   0.   0.   0.   0.   0.02 0.  ]\n",
      " [0.01 0.   0.94 0.05 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.91 0.   0.01 0.   0.02 0.03 0.02]\n",
      " [0.   0.   0.   0.   0.93 0.   0.   0.   0.   0.07]\n",
      " [0.   0.   0.   0.   0.   0.97 0.01 0.   0.   0.02]\n",
      " [0.   0.   0.   0.   0.   0.   1.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.99 0.01 0.  ]\n",
      " [0.   0.02 0.   0.02 0.   0.   0.   0.   0.95 0.  ]\n",
      " [0.   0.   0.   0.03 0.   0.02 0.   0.   0.01 0.93]]\n"
     ]
    }
   ],
   "source": [
    "# Determine the compute time\n",
    "start_STOPWATCH = time.time()\n",
    "\n",
    "# Rerun knn without pca again without confusion matrix\n",
    "knnClassifierManual = kNNClassifierManual()\n",
    "knnClassifierManual.train(X_train, y_train)\n",
    "test(X_test, y_test, knnClassifierManual)\n",
    "\n",
    "# Record time\n",
    "print(\"\\n\\nKNN Classifier without PCA Computational Time: \", time.time() - start_STOPWATCH, \" s\")\n",
    "\n",
    "# display confusion matrix for your KNN classifier without PCA all the training examples\n",
    "knnClassifierManual = kNNClassifierManual()\n",
    "knnClassifierManual.train(X_train, y_train)\n",
    "\n",
    "# Get the confusion matrix and the overall accuracy of the knnClassifierManual\n",
    "M_knn, acc_knn = Confusion(X_test, y_test, knnClassifierManual)\n",
    "\n",
    "# Print the accuracy\n",
    "print ('KNN classifier without PCA accuracy: %f'%acc_knn)\n",
    "VisualizeConfussion(M_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuQfPRnEpM9c"
   },
   "source": [
    "**Question:**<br>\n",
    "Is the testing time for PCA KNN classifier more or less than that for KNN classifier? Comment on why it differs if it does.\n",
    "\n",
    "**Solution:**<br>\n",
    "The testing time for the PCA KNN classifier is shorter than the KNN classifier wihout PCA because PCA helps to reduce the dimensions of the training data set features. As a result, PCA-KNN classifier takes lesser computational time during the training process as compared to the KNN classifier without PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8ol8VCDpV8Q"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>\n",
    "\n",
    "## Problem 2: Deep learning [28 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYf3GsdmpfvS"
   },
   "source": [
    "### Problem 2.1 Initial setup [1 pts]\n",
    "\n",
    "Follow the directions on https://pytorch.org/get-started/locally/ to install Pytorch on your computer. \n",
    "\n",
    "Note: You will not need GPU support for this assignment so don't worry if you don't have one. Furthermore, installing with GPU support is often more difficult to configure so it is suggested that you install the CPU only version. TA's will not provide any support related to GPU or CUDA.\n",
    "\n",
    "Run the torch import statements below to verify your instalation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQC44M9Rp1VR"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ai7Lktn5tLBz"
   },
   "source": [
    "In this problem, we will use the full dataset of MNIST database with 28x28 pixel images of digits.\n",
    "\n",
    "Download the MNIST data from http://yann.lecun.com/exdb/mnist/.\n",
    "\n",
    "Download the 4 zipped files, extract them into one folder, and change the variable 'path' in the code below. (Code taken from https://gist.github.com/akesling/5358964 )\n",
    "\n",
    "Plot one random example image corresponding to each label from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6owsEdLttV9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "# Change path as required\n",
    "path = \"./mnist/\"\n",
    "\n",
    "def read(dataset = \"training\", datatype='images'):\n",
    "    \"\"\"\n",
    "    Python function for importing the MNIST data set.  It returns an iterator\n",
    "    of 2-tuples with the first element being the label and the second element\n",
    "    being a numpy.uint8 2D array of pixel data for the given image.\n",
    "    \"\"\"\n",
    "\n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "\n",
    "    # Load everything in some numpy arrays\n",
    "    with open(fname_lbl, 'rb') as flbl:\n",
    "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "    with open(fname_img, 'rb') as fimg:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "    \n",
    "    if(datatype=='images'):\n",
    "        get_data = lambda idx: img[idx]\n",
    "    elif(datatype=='labels'):\n",
    "        get_data = lambda idx: lbl[idx]\n",
    "\n",
    "    # Create an iterator which returns each image in turn\n",
    "    for i in range(len(lbl)):\n",
    "        yield get_data(i)\n",
    "        \n",
    "X_train=np.array(list(read('training','images')))\n",
    "print(X_train.shape)\n",
    "y_train=np.array(list(read('training','labels')))\n",
    "X_test=np.array(list(read('testing','images')))\n",
    "print(X_test.shape)\n",
    "y_test=np.array(list(read('testing','labels')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wu-weDbqEAY"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>\n",
    "\n",
    "### Problem 2.2:  Training with PyTorch [8 pts]\n",
    "Below is some helper code to train your deep networks. \n",
    "Complete the train function for DNN below. You should write down the training operations in this function. That means, for a batch of data you have to initialize the gradients, forward propagate the data, compute error, do back propagation and finally update the parameters. This function will be used in the following questions with different networks.\n",
    "You can look at https://pytorch.org/tutorials/beginner/pytorch_with_examples.html for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ky0FksEwqDta"
   },
   "outputs": [],
   "source": [
    "# base class for your deep neural networks. It implements the training loop (train_net).\n",
    "\n",
    "\n",
    "import torch.nn.init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def train_net(self, X_train, y_train, epochs=1, batchSize=50):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        #self.lc\n",
    "        # Initialize learning rate.\n",
    "        learning_Rate = 1e-3\n",
    "        \n",
    "        # Create mean Cross Entropy object\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        #loss = nn.MSELoss()\n",
    "        \n",
    "        # Set the optimization parameters with Stochastic Gradient Descent (SGD)\n",
    "        #optimizer = optim.SGD(self.parameters(), lr = learning_Rate)\n",
    "        #print(self.parameters())\n",
    "        optimizer = optim.Adam(nn.ParameterList(self.parameters()), lr = learning_Rate)\n",
    "        \n",
    "        # Iterate through number of epochs.\n",
    "        for EPOCH in range(0, epochs):\n",
    "            \n",
    "            #for i, (data, label) in enumerate(DataBatch(X_train,y_train,batchSize,shuffle=True)):\n",
    "            for data,label in tqdm(DataBatch(X_train,y_train,batchSize,shuffle=True), total=len(X_train)//batchSize):\n",
    "                \n",
    "                # Initialize the gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Torch array instead of numpy array\n",
    "                data = Variable(torch.FloatTensor(data))\n",
    "                label = Variable(torch.LongTensor(label))\n",
    "                \n",
    "                # Check data shape\n",
    "                #print(data.shape)\n",
    "                #print(label.shape)\n",
    "                \n",
    "                # Forward propagate data\n",
    "                y_predict = self.forward(data)\n",
    "                \n",
    "                # Compute error\n",
    "                err = loss(y_predict, label)\n",
    "                \n",
    "                # Back propagate data\n",
    "                err.backward()\n",
    "                \n",
    "                # Update Parameters\n",
    "                optimizer.step()\n",
    "                \n",
    "            #print(err)     \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        #print(\"Called\")\n",
    "        inputs = Variable(torch.FloatTensor(x))\n",
    "        prediction = self.forward(inputs)\n",
    "        return np.argmax(prediction.data.cpu().numpy(), 1)\n",
    "\n",
    "# helper function to get weight variable\n",
    "def weight_variable(shape):\n",
    "    initial = torch.Tensor(truncnorm.rvs(-1/0.01, 1/0.01, scale=0.01, size=shape))\n",
    "    return Parameter(initial, requires_grad=True)\n",
    "\n",
    "# helper function to get bias variable\n",
    "def bias_variable(shape):\n",
    "    initial = torch.Tensor(np.ones(shape)*0.1)\n",
    "    return Parameter(initial, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HYVuzbtosJo"
   },
   "outputs": [],
   "source": [
    "# example linear classifier - input connected to output\n",
    "# you can take this as an example to learn how to extend DNN class\n",
    "class LinearClassifier(DNN):\n",
    "    def __init__(self, in_features=28*28, classes=10):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        # in_features=28*28\n",
    "        self.weight1 = weight_variable((classes, in_features))\n",
    "        self.bias1 = bias_variable((classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # linear operation\n",
    "        y_pred = torch.addmm(self.bias1, x.view(list(x.size())[0], -1), self.weight1.t())\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "X_train=np.float32(np.expand_dims(X_train,-1))/255\n",
    "X_train=X_train.transpose((0,3,1,2))\n",
    "\n",
    "X_test=np.float32(np.expand_dims(X_test,-1))/255\n",
    "X_test=X_test.transpose((0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-UGSj6FqRKf"
   },
   "outputs": [],
   "source": [
    "# test the example linear classifier (note you should get around 90% accuracy\n",
    "# for 10 epochs and batchsize 50)\n",
    "linearClassifier = LinearClassifier()\n",
    "linearClassifier.train_net(X_train, y_train, epochs=10)\n",
    "\n",
    "print ('Linear classifier accuracy: %f'%test(X_test, y_test, linearClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RA5688oyNTu"
   },
   "outputs": [],
   "source": [
    "# display confusion matrix\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "M_dnn, acc_dnn = Confusion(X_test, y_test, linearClassifier)\n",
    "VisualizeConfussion(M_dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNzcCiLr0AU8"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>\n",
    "\n",
    "### Problem 2.3: Single Layer Perceptron [3 pts]\n",
    "The simple linear classifier implemented in the cell already performs quite well. Plot the filter weights corresponding to each output class (weights, not biases) as images. (Normalize weights to lie between 0 and 1 and use color maps like 'inferno' or 'plasma' for good results). Comment on what the weights look like and why that may be so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8S3dYZgzzT_"
   },
   "outputs": [],
   "source": [
    "# Plot filter weights corresponding to each class, you may have to reshape them to make sense out of them\n",
    "# linearClassifier.weight1.data will give you the first layer weights\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "# Get the first layer weights\n",
    "weights_array = linearClassifier.weight1.data\n",
    "\n",
    "#print(weights_array.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "for idx in range(0, weights_array.shape[0]):\n",
    "    \n",
    "    # Plot it.\n",
    "    # Extract one weight from the array\n",
    "    img = weights_array[idx, :]\n",
    "    \n",
    "    # Normalize it\n",
    "    img = (img - img.min()) / (img.max()- img.min())\n",
    "    \n",
    "    # Create subplots\n",
    "    plt.subplot(2, 5, idx+1)\n",
    "    \n",
    "    # Plot title\n",
    "    plot_Header = \"Number: \"+ str(idx) \n",
    "    \n",
    "    # Include headers\n",
    "    plt.title(plot_Header) \n",
    "    \n",
    "    # Reshape the array to 28 x 28 before plotting\n",
    "    plt.imshow(img.reshape((28, 28)), cmap ='inferno') # Plot the sample image\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmQUOBNg0PkW"
   },
   "source": [
    "#### Comments on weights\n",
    "The images above illustrates that the weights that are feeding into their corresponding output neuron, which is responsible for classifying a specific digit, consist of the shape of that specific number. This is because each specific output neuron will generate high activaion in the first layer when it encounters an image that looks like a specific number from that weight image above, which is also known as a filter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJBWgsBE0S7K"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>\n",
    "\n",
    "### Problem 2.4: Multi Layer Perceptron (MLP) [8 pts]\n",
    "Here you will implement an MLP. The MLP should consist of 2 layers (matrix multiplication and bias offset) that map to the following feature dimensions:\n",
    "\n",
    "* 28x28 -> hidden (100)\n",
    "* hidden -> classes\n",
    "\n",
    "* The hidden layer should be followed with a ReLU nonlinearity. The final layer should not have a nonlinearity applied as we desire the raw logits output.\n",
    "* The final output of the computation graph should be stored in self.y as that will be used in the training.\n",
    "\n",
    "Display the confusion matrix and accuracy after training. Note: You should get ~ 97 % accuracy for 10 epochs and batch size 50.\n",
    "\n",
    "Plot the filter weights corresponding to the mapping from the inputs to the first 10 hidden layer outputs (out of 100). Do the weights look similar to the weights plotted in the previous problem? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ss2lUgpL0JRh"
   },
   "outputs": [],
   "source": [
    "class MLPClassifer(DNN):\n",
    "    def __init__(self, in_features=28*28, classes=10, hidden=100):\n",
    "        super(MLPClassifer, self).__init__()\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        # Defining model\n",
    "        self.weight1 = weight_variable((hidden, in_features))\n",
    "        self.bias1 = bias_variable((hidden))\n",
    "        self.weight2 = weight_variable((classes, hidden))\n",
    "        self.bias2 = bias_variable((classes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        # Linear operation\n",
    "        hidden_layer = torch.addmm(self.bias1, x.view(list(x.size())[0], -1), self.weight1.t())\n",
    "        m_ReLU = nn.ReLU()\n",
    "        y_pred = torch.addmm(self.bias2, m_ReLU(hidden_layer), self.weight2.t())\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "mlpClassifer = MLPClassifer()\n",
    "mlpClassifer.train_net(X_train, y_train, epochs=10, batchSize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-4xraHl0muj"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "M_mlp,acc_mlp = Confusion(X_test, y_test, mlpClassifer)\n",
    "print ('MLP classifier accuracy: %f'%acc_mlp)\n",
    "VisualizeConfussion(M_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLD0yjHH0bVU"
   },
   "outputs": [],
   "source": [
    "# Plot filter weights\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "# Get the first layer weights\n",
    "weights_array = mlpClassifer.weight1.data\n",
    "\n",
    "#print(weights_array.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "for idx in range(0, 10):\n",
    "    \n",
    "    # Plot it.\n",
    "    # Extract one weight from the array\n",
    "    img = weights_array[idx, :]\n",
    "    \n",
    "    # Normalize it\n",
    "    img = (img - img.min()) / (img.max()- img.min())\n",
    "    \n",
    "    # Create subplots\n",
    "    plt.subplot(2, 5, idx+1)\n",
    "    \n",
    "    # Plot title\n",
    "    plot_Header = \"Number: \"+ str(idx) \n",
    "    \n",
    "    # Include headers\n",
    "    plt.title(plot_Header) \n",
    "    \n",
    "    # Reshape the array to 28 x 28 before plotting\n",
    "    plt.imshow(img.reshape((28, 28)), cmap ='inferno') # Plot the sample image\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pCLEVJ_1F66"
   },
   "source": [
    "#### Comments on weights:\n",
    "\n",
    "The weights do not look like as clearly as numbers like we observed in the previous case. Some of them look like number 2, some look like a combinantion of multiple numbers and some filters do not look like numbers at all. \n",
    "\n",
    "Linear classifier was a special case where the output neuron is simply dot product with input image plus a bias and hence we had all filters looking like numbers. It may not be so here.\n",
    "\n",
    "In above figure, that look somewhat like 2 (filter 5, filter 7. filter 8) points that the network is trying to fit different hidden neurons to the same hand-written digits with possibly different neuron activations for different strokes. But it's unclear what exactly other filters and if they represent anything tangible.\n",
    "\n",
    "So, eventhough we see few patterns for the filters, we still have 100 hidden neurons and a ReLU non-linearity. It is very difficult to figure out what the neural network actually learns for each filter at the hidden neurons because it has immense flexibility with the 100 units. This aspect essentially reflects in the 'hidden' part of the name 'hidden layer'. In conclusion, as networks grow deep and we keep adding non-linearities, the analysis of what network is doing becomes very difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBC6s9qQ1KKj"
   },
   "source": [
    "<div style=\"page-break-after: always; visibility: hidden\"> \n",
    "\\pagebreak \n",
    "</div>\n",
    "\n",
    "### Problem 2.5: Convolutional Neural Network (CNN) [8 pts]\n",
    "Here you will implement a CNN with the following architecture:\n",
    "\n",
    "* n=5\n",
    "* ReLU( Conv(kernel_size=5x5, stride=2, output_features=n) )\n",
    "* ReLU( Conv(kernel_size=5x5, stride=2, output_features=n*2) )\n",
    "* ReLU( Linear(hidden units = 64) )\n",
    "* Linear(output_features=classes)\n",
    "\n",
    "So, 2 convolutional layers, followed by 1 fully connected hidden layer and then the output layer\n",
    "\n",
    "Display the confusion matrix and accuracy after training. You should get around ~ 98 % accuracy for 10 epochs and batch size 50.<br><br>\n",
    "**Note: You are not allowed to use torch.nn.Conv2d() and torch.nn.Linear(), Using these will lead to deduction of points. Use the declared conv2d(), weight_variable() and bias_variable() functions.** Although, in practice, when you move forward after this class you will use torch.nn.Conv2d() which makes life easier and hides all the operations underneath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OhmF0NM1Clj"
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, stride, bias=None):\n",
    "    # x: input\n",
    "    # W: weights (out, in, kH, kW)\n",
    "    return F.conv2d(x, W, bias, stride=stride, padding=2)\n",
    "\n",
    "# Defining a Convolutional Neural Network\n",
    "class CNNClassifer(DNN):\n",
    "    def __init__(self, classes=10, n=5):\n",
    "        super(CNNClassifer, self).__init__()\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        # Input Channel because of grayscale image\n",
    "        in_channel = 1\n",
    "        # Kernel Size\n",
    "        kernel_size_r = 5 # Row\n",
    "        kernel_size_c = 5 # Column\n",
    "        # Hidden Units\n",
    "        hidden_units = 64\n",
    "        \n",
    "        # Defining model\n",
    "        self.weight1 = weight_variable((n, in_channel, kernel_size_r, kernel_size_c))\n",
    "        self.bias1 = bias_variable((n))\n",
    "        \n",
    "        self.weight2 = weight_variable((n*2, n, kernel_size_r, kernel_size_c))\n",
    "        self.bias2 = bias_variable((n*2))\n",
    "        \n",
    "        self.weight3 = weight_variable((hidden_units, 7*7*n*2))\n",
    "        self.bias3 = bias_variable((hidden_units))\n",
    "        \n",
    "        self.weight4 = weight_variable((classes, hidden_units))\n",
    "        self.bias4 = bias_variable((classes))\n",
    "       \n",
    "    def forward(self, x):\n",
    "        \"\"\" ==========\n",
    "        YOUR CODE HERE\n",
    "        ========== \"\"\"\n",
    "        # Number of Strides\n",
    "        num_Strides = 2\n",
    "        \n",
    "        # Convolution Operations\n",
    "        convovle_1 = conv2d(x.view(list(x.size())[0], 1, 28, 28), self.weight1, stride = num_Strides, bias = self.bias1) \n",
    "        conv1_ReLU = nn.ReLU()\n",
    "        convovle_2 = conv2d(conv1_ReLU(convovle_1), self.weight2, stride = num_Strides, bias = self.bias2)\n",
    "        conv2_ReLU = nn.ReLU()\n",
    "        \n",
    "        # Linear Operation\n",
    "        fully_connected = convovle_2.view(list(conv2_ReLU(convovle_2).size())[0], 490)\n",
    "        hidden_layer = torch.addmm(self.bias3, fully_connected, self.weight3.t())\n",
    "        m_ReLU = nn.ReLU()\n",
    "        y = torch.addmm(self.bias4, m_ReLU(hidden_layer), self.weight4.t())\n",
    "       \n",
    "        return y\n",
    "    \n",
    "cnnClassifer = CNNClassifer()\n",
    "cnnClassifer.train_net(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWkNhBgf1Sf3"
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "\"\"\" ==========\n",
    "YOUR CODE HERE\n",
    "========== \"\"\"\n",
    "M_cnn,acc_cnn = Confusion(X_test, y_test, cnnClassifer)\n",
    "print ('Convolution Neural Network classifier accuracy: %f'%acc_cnn)\n",
    "VisualizeConfussion(M_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHx9gSiK1xVp"
   },
   "source": [
    "* Note that the MLP/ConvNet approaches lead to an accuracy a little higher than the K-NN approach. \n",
    "* In general, Neural net approaches lead to significant increase in accuracy, but in this case since the problem is not too hard, the increase in accuracy is not very high.\n",
    "* However, this is still quite significant considering the fact that the ConvNets we've used are relatively simple while the accuracy achieved using K-NN is with a search over 60,000 training images for every test image.\n",
    "* You can look at the performance of various machine learning methods on this problem at http://yann.lecun.com/exdb/mnist/\n",
    "* You can learn more about neural nets/ pytorch at<br> https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "* You can play with a demo of neural network created by Daniel Smilkov and Shan Carter at https://playground.tensorflow.org/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "HW4.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
